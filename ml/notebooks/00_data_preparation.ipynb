{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Split Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, json\n",
    "from pathlib import Path\n",
    "from hashlib import blake2b\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Locate repo root and add to path\n",
    "HERE = Path.cwd().resolve()\n",
    "REPO_ROOT = None\n",
    "for _p in [HERE] + list(HERE.parents):\n",
    "    if (_p / 'ml').exists() and (_p / 'data').exists():\n",
    "        REPO_ROOT = _p\n",
    "        break\n",
    "assert REPO_ROOT, f'Cannot find repo root from {HERE}'\n",
    "os.chdir(REPO_ROOT)\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "from ml.notebooks.experiment_config import *\n",
    "\n",
    "print('[*] Repo root        :', REPO_ROOT)\n",
    "print('[*] Random seed      :', RANDOM_SEED)\n",
    "print('[*] Merged parquet   :', MERGED_PARQUET)\n",
    "print('[*] Zeek-only out    :', ZEEK_ONLY_PARQUET)\n",
    "print('[*] Zeek+eBPF out    :', ZEEK_EBPF_PARQUET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build feature-set parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert MERGED_PARQUET.exists(), f'Missing: {MERGED_PARQUET}'\n",
    "\n",
    "report_dir = REPORTS_DIR / 'make_datasets'\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "subprocess.run([\n",
    "    'python3', 'ml/data_prep/make_datasets.py',\n",
    "    '--in_parquet',  str(MERGED_PARQUET),\n",
    "    '--out_baseline', str(ZEEK_ONLY_PARQUET),\n",
    "    '--out_enhanced', str(ZEEK_EBPF_PARQUET),\n",
    "    '--report_dir',  str(report_dir),\n",
    "], check=True)\n",
    "\n",
    "# Quick sanity\n",
    "for p in [ZEEK_ONLY_PARQUET, ZEEK_EBPF_PARQUET]:\n",
    "    df_tmp = pd.read_parquet(p, columns=['label_family'])\n",
    "    print(f'[+] {p.name}: {len(df_tmp):,} rows, labels: {sorted(df_tmp[\"label_family\"].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session-aware temporal splits (PRIMARY strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[*] SESSION-AWARE TEMPORAL SPLIT')\n",
    "print('Groups flows by (src_ip, dst_ip, proto, day), orders groups by earliest')\n",
    "print('timestamp, then assigns chronologically.  Prevents both time and session leakage.')\n",
    "\n",
    "for label, parquet_path, out_dir in [\n",
    "    ('zeek_only', ZEEK_ONLY_PARQUET, SPLITS_SESSION_TEMPORAL_BASELINE),\n",
    "    ('zeek_ebpf', ZEEK_EBPF_PARQUET, SPLITS_SESSION_TEMPORAL_EBPF),\n",
    "]:\n",
    "    print(f'\\n\\n[*] {label}')\n",
    "    subprocess.run([\n",
    "        'python3', 'ml/data_prep/split_session_temporal.py',\n",
    "        '--in_parquet', str(parquet_path),\n",
    "        '--out_dir',    str(out_dir),\n",
    "        '--train_frac', '0.70',\n",
    "        '--val_frac',   '0.15',\n",
    "        '--test_frac',  '0.15',\n",
    "        '--seed',       str(RANDOM_SEED),\n",
    "    ], check=True)\n",
    "\n",
    "print('\\n[+] Session-temporal splits done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within-day time splits (COMPARISON reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[*] WITHIN-DAY TIME SPLIT')\n",
    "print('Splits within each day by timestamp.  Prevents time leakage but NOT session leakage.')\n",
    "print('Kept for direct comparison with the session-temporal results.')\n",
    "\n",
    "for label, parquet_path, out_dir in [\n",
    "    ('zeek_only', ZEEK_ONLY_PARQUET, SPLITS_WITHIN_DAY_BASELINE),\n",
    "    ('zeek_ebpf', ZEEK_EBPF_PARQUET, SPLITS_WITHIN_DAY_EBPF),\n",
    "]:\n",
    "    print(f'\\n\\n[*] {label}')\n",
    "    subprocess.run([\n",
    "        'python3', 'ml/data_prep/split_days_auto.py',\n",
    "        '--in_parquet', str(parquet_path),\n",
    "        '--out_dir',    str(out_dir),\n",
    "        '--protocol',   'within_day_time',\n",
    "        '--seed',       str(RANDOM_SEED),\n",
    "        '--train_frac', '0.70',\n",
    "        '--val_frac',   '0.15',\n",
    "        '--test_frac',  '0.15',\n",
    "    ], check=True)\n",
    "\n",
    "print('\\n[+] Within-day splits done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day-holdout splits (STRESS-TEST: unseen days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[*] DAY HOLDOUT SPLIT (Primary preset: Mon/Tue/Wed train, Thu val, Fri test)')\n",
    "print('WARNING: some attack families only appear on one day and will be unseen in train.')\n",
    "print('Used only as a generalisation stress-test.')\n",
    "\n",
    "for label, parquet_path, out_dir in [\n",
    "    ('zeek_only', ZEEK_ONLY_PARQUET, SPLITS_DAY_HOLDOUT_BASELINE),\n",
    "    ('zeek_ebpf', ZEEK_EBPF_PARQUET, SPLITS_DAY_HOLDOUT_EBPF),\n",
    "]:\n",
    "    print(f'\\n\\n[*] {label}')\n",
    "    subprocess.run([\n",
    "        'python3', 'ml/data_prep/split_by_day.py',\n",
    "        '--in_parquet', str(parquet_path),\n",
    "        '--out_dir',    str(out_dir),\n",
    "        '--split',      'primary',\n",
    "    ], check=True)\n",
    "\n",
    "print('\\n[+] Day-holdout splits done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage & label-coverage diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hash_rows(df: pd.DataFrame, cols: list) -> set:\n",
    "    use = df[cols].copy()\n",
    "    for c in cols:\n",
    "        use[c] = use[c].astype(str)\n",
    "    joined = use.apply(lambda r: '||'.join(r.values.tolist()), axis=1)\n",
    "    return set(joined.apply(lambda s: blake2b(s.encode('utf-8'), digest_size=8).hexdigest()))\n",
    "\n",
    "def leakage_report(splits_dir: Path, name: str):\n",
    "    splits_dir = Path(splits_dir)\n",
    "    if not splits_dir.exists():\n",
    "        print(f'[!] Skipping {name} — directory not found: {splits_dir}')\n",
    "        return\n",
    "\n",
    "    train = pd.read_parquet(splits_dir / 'train.parquet')\n",
    "    val   = pd.read_parquet(splits_dir / 'val.parquet')\n",
    "    test  = pd.read_parquet(splits_dir / 'test.parquet')\n",
    "\n",
    "    print(f'Leakage check: {name}')\n",
    "    print(f'rows  train/val/test: {len(train):,} / {len(val):,} / {len(test):,}')\n",
    "\n",
    "    # 5-tuple session overlap\n",
    "    tuple_cols = [c for c in ['orig_h','resp_h','orig_p','resp_p','proto','src_ip','dst_ip'] if c in train.columns]\n",
    "    if tuple_cols:\n",
    "        ht = _hash_rows(train, tuple_cols[:5])\n",
    "        hv = _hash_rows(val,   tuple_cols[:5])\n",
    "        hs = _hash_rows(test,  tuple_cols[:5])\n",
    "        print(f'5-tuple overlap  train∩val={len(ht&hv):,}  train∩test={len(ht&hs):,}  val∩test={len(hv&hs):,}')\n",
    "        if len(ht&hs) > 0:\n",
    "            print(f'  -> {len(ht&hs)/max(len(hs),1)*100:.1f}% of test sessions seen in train (session leakage if high)')\n",
    "    else:\n",
    "        print('[!] No 5-tuple columns found.')\n",
    "\n",
    "    # Exact-row duplicate check\n",
    "    full_cols = [c for c in train.columns if c not in ['ts','start_ts','end_ts','t_end']][:50]\n",
    "    hf_tr = _hash_rows(train, full_cols)\n",
    "    hf_va = _hash_rows(val,   full_cols)\n",
    "    hf_te = _hash_rows(test,  full_cols)\n",
    "    print(f'Exact-row overlap train∩val={len(hf_tr&hf_va):,}  train∩test={len(hf_tr&hf_te):,}')\n",
    "\n",
    "    # Label coverage\n",
    "    lc = 'label_family'\n",
    "    if lc in train.columns:\n",
    "        tr_lbl = set(train[lc].astype(str).unique())\n",
    "        va_lbl = set(val[lc].astype(str).unique())\n",
    "        te_lbl = set(test[lc].astype(str).unique())\n",
    "        unseen_val  = sorted(va_lbl - tr_lbl)\n",
    "        unseen_test = sorted(te_lbl - tr_lbl)\n",
    "        print(f'Attack families unseen in train but in val : {unseen_val}')\n",
    "        print(f'Attack families unseen in train but in test: {unseen_test}')\n",
    "\n",
    "# Run for all three split strategies\n",
    "leakage_report(SPLITS_SESSION_TEMPORAL_BASELINE, 'session_temporal / zeek_only')\n",
    "leakage_report(SPLITS_SESSION_TEMPORAL_EBPF,     'session_temporal / zeek_ebpf')\n",
    "leakage_report(SPLITS_WITHIN_DAY_BASELINE,        'within_day_time  / zeek_only')\n",
    "leakage_report(SPLITS_DAY_HOLDOUT_BASELINE,       'day_holdout      / zeek_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label distribution overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_label_dist(splits_dir: Path, title: str):\n",
    "    splits_dir = Path(splits_dir)\n",
    "    if not splits_dir.exists():\n",
    "        print(f'[!] Skipping {title}')\n",
    "        return\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\n",
    "    for ax, split in zip(axes, ['train', 'val', 'test']):\n",
    "        df = pd.read_parquet(splits_dir / f'{split}.parquet', columns=['label_family'])\n",
    "        vc = df['label_family'].value_counts()\n",
    "        vc.plot(kind='barh', ax=ax)\n",
    "        ax.set_title(f'{split} ({len(df):,} rows)')\n",
    "        ax.set_xlabel('Count')\n",
    "    fig.suptitle(title, fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_DIR / f'label_dist_{title.replace(\" \",\"_\").replace(\"/\",\"-\")}.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "plot_label_dist(SPLITS_SESSION_TEMPORAL_BASELINE, 'session_temporal / zeek_only')\n",
    "plot_label_dist(SPLITS_WITHIN_DAY_BASELINE,        'within_day_time  / zeek_only')\n",
    "plot_label_dist(SPLITS_DAY_HOLDOUT_BASELINE,       'day_holdout      / zeek_only')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
